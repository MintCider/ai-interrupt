# AI 插嘴插件

## 介绍

本插件工作于 [海豹骰点核心](https://github.com/sealdice/sealdice-core)，并基于其 [TS 模板库](https://github.com/sealdice/sealdice-js-ext-template) 实现。

本插件通过接入大模型 API 并随机在群聊中发言，创造更为生动的骰子使用体验。

## 使用

### 安装

在本项目 Release 页面中，直接下载最新编译的 JS 文件，或 [点击这里](https://github.com/MintCider/ai-interrupt/releases/latest/download/ai-interrupt.js) 下载。随后上传到海报核心即可。

### 命令

可以使用 .interrupt on/off/status 来开启/关闭/查看 AI 插嘴功能，可以使用 .interrupt clear 清除储存的历史记录。

### 配置

目前，本插件的配置项分为「基础设置」、「视觉大模型设置」、「文本大模型设置」三个部分。

#### 基础设置

* **插嘴的概率：**
  填入一个 0 - 1 的小数。例如，0.5 意味着收到一条消息后，骰子有 50% 的概率进行回应。

* **历史记录保存的最大长度：**
  插件会存储群聊的最新聊天记录，以保证回复的内容契合上下文。存储的聊天记录越长，AI 对上下文的理解越好，但 token 消耗也越多。

* **允许触发插嘴的最小历史记录长度：**
  当存储的历史记录长度小于这一配置时，不会触发插嘴，以免生成的内容过于无关。

* **开启关闭插件所需的权限等级：**
  权限等级数字的含义请见 [海豹手册](https://mintcider.github.io/sealdice-manual-next/advanced/js_example.html#%E6%9D%83%E9%99%90%E8%AF%86%E5%88%AB)。只有高于或等于此权限等级的用户才可以正常触发 on/off/clear 命令。

* **骰子昵称：**
  如题，请务必填入。

* **骰子 QQ 号：**
  如题，请务必填入。

* **被 @ 时是否必定回复（无论历史记录长短）：**
  开启此功能后，当骰子被提及（包括被回复），骰子必定会回复，无论存储的聊天记录长度如何。

* **插嘴时是否回复触发消息：**
  开启此功能后，当骰子插嘴时，会「回复」触发插嘴的消息。当开启视觉大模型等功能后，插件的延迟可能会增大，此功能可以减少骰子延迟回复的突兀感。

* **打印 prompt 日志：**
  开启此功能后，会在调用 API 前，将完整的 prompt 信息输出到日志中。开启后可以排查生成的 prompt 是否符合预期。

* **打印 API Response 日志：**
  开启此功能后，会在调用 API 后，将完整的 response 信息输出到日志中。开启后可以排查 API 是否正确返回符合格式的信息。

#### 视觉大模型设置

* **是否解析图像：**
  开启此功能后，插件会试图调用视觉大模型，用文字描述聊天记录中的图像信息。需要注意流量、token 消耗，以及由此引入的延迟。

* **视觉大模型的系统提示：**
  如题。

* **视觉大模型的 API URL：**
  如题。

* **视觉大模型的 API Key：**
  如题。

* **视觉大模型的型号：**
  如题。需要保证此模型支持以 URL 的方式传入图片链接。例如，`glm-4v` 支持此种调用方式，但是 `glm-4v-plus` 不支持。

* **视觉大模型的最大生成长度：**
  如题。

* **image_temperature：**
  默认为 -1，即使用模型的默认参数。如果你不确定这是什么，就不要修改。

* **image_top_p：**
  默认为 -1，即使用模型的默认参数。如果你不确定这是什么，就不要修改。

#### 文本大模型设置

v0.1.0 版本引入了 schema 机制，以增强调用大模型的灵活性。在存储历史消息时，会储存用户的昵称、QQ 号以及消息本身。

在构建 prompt 时，对于 system prompt、用户消息以及骰子产生的回复，会分别根据 `system_schema`、`user_schema` 以及 `assistant_schema`，替换占位符后压入 prompt。其中，`user_schema` 的占位符使用实际存储的数据替换。而 `system_schema` 与 `assistant_schema` 则使用插件配置项中的昵称与 QQ 号替换。

需要特别注意的是，对于 `assistant_schema` 而言，`<message>` 的实际内容取决于 `retrieve_schema`。`retrieve_schema` 应是一个带捕获组的正则表达式。其内的 `<nickname>` 与 `<id>` 首先会被插件配置项中的数据替换，随后第一个捕获组所捕获的内容，会被作为插件的实际回复所取回，并存入历史聊天记录。

`system_schema`、`user_schema`、`assistant_schema` 以及 `retrieve_schema` 的默认值提供了一个最小可工作范例。

* **文本大模型的系统提示格式：**
  请认真阅读上面关于 schema 的描述后修改。

* **文本大模型的用户消息 prompt 格式：**
  请认真阅读上面关于 schema 的描述后修改。

* **文本大模型的骰子消息 prompt 格式：**
  请认真阅读上面关于 schema 的描述后修改。

* **从大模型回复提取骰子消息的正则表达式：**
  请认真阅读上面关于 schema 的描述后修改。注意区分全角半角，注意要有捕获组。

* **文本大模型的 API URL：**
  如题。

* **文本大模型的 API Key：**
  如题。

* **文本大模型的型号：**
  如题。

* **文本大模型的最大生成长度：**
  如题。

* **temperature：**
  默认为 -1，即使用模型的默认参数。如果你不确定这是什么，就不要修改。

* **top_p：**
  默认为 -1，即使用模型的默认参数。如果你不确定这是什么，就不要修改。
